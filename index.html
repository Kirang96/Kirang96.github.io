<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Kiran George - Portfolio</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 0;
      background: #f9f9f9;
      color: #333;
      line-height: 1.6;
    }

    .container {
      width: 90%;
      max-width: 1100px;
      margin: auto;
      overflow: hidden;
      padding: 2rem 0;
    }

    /* Profile Section */
    .profile {
      max-width: 650px; /* ONLY THIS SECTION IS NARROWER */
      margin: 0 auto 3rem;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      text-align: center;
    }

    .profile img {
      border-radius: 50%;
      width: 180px;
      height: 180px;
      object-fit: cover;
      margin-bottom: 1rem;
      border: 3px solid #555;
      flex-shrink: 0;
    }

    .profile-text h1 {
      margin: 0;
      font-size: 2.5rem;
    }

    .profile-text p {
      margin: 0.5rem 0;
      font-size: 1.2rem;
    }

    .links a {
      margin: 0 0.5rem;
      text-decoration: none;
      color: #0077cc;
    }

    @media (min-width: 768px) {
      .profile {
        flex-direction: row;
        text-align: left;
        align-items: flex-start; 
      }
      .profile img {
        margin-right: 2rem;
        margin-bottom: 0;
      }
    }

    /* --- EXPERIENCE & EDUCATION TIMELINE SECTION --- */
    .timeline {
      list-style: none;
      padding: 0;
      margin: 2rem auto;
      max-width: 800px; /* Back to original width */
      position: relative; 
    }
    
    .timeline::before {
        content: '';
        position: absolute;
        top: 0;
        bottom: 0;
        left: 25px;
        width: 2px;
        background-color: #e9ecef;
    }

    .timeline-item {
      display: flex;
      align-items: flex-start;
      margin-bottom: 2.5rem;
      position: relative;
    }

    .timeline-logo {
      flex-shrink: 0;
      width: 50px;
      height: 50px;
      border-radius: 50%;
      background: #f9f9f9;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 1.5rem;
      font-weight: bold;
      color: #495057;
      margin-right: 1.5rem;
      border: 2px solid #e9ecef;
      z-index: 1;
    }

    .timeline-logo img {
        width: 100%;
        height: 100%;
        object-fit: contain;
    }

    .timeline-content {
      flex-grow: 1;
    }

    .timeline-content h3 {
      margin: 0;
      font-size: 1.2rem;
      font-weight: 600;
    }

    .timeline-content span {
      font-size: 0.9rem;
      color: #666;
      display: block;
      margin-top: 2px;
    }

    .timeline-content p, .timeline-content ul {
      margin: 0.75rem 0 0 0;
      line-height: 1.5;
    }
    
    .timeline-content ul {
        padding-left: 20px;
    }

    /* --- PROJECTS SECTION --- */
    #projects {
        padding: 2rem 0;
    }

    .projects-grid {
        display: grid;
        grid-template-columns: repeat(3, 1fr); /* Back to 3 columns */
        gap: 1.5rem;
        max-width: 1100px; /* Back to original width */
        margin: 2rem auto 0;
    }

    .card {
        background: #fff;
        border-radius: 8px;
        box-shadow: 0 4px 8px rgba(0,0,0,0.05);
        transition: transform 0.2s ease-in-out, box-shadow 0.2s ease-in-out;
        display: flex;
        flex-direction: column;
    }

    .card:hover {
        transform: translateY(-5px);
        box-shadow: 0 8px 16px rgba(0,0,0,0.1);
    }
    
    .card-content {
        padding: 1.5rem;
        flex-grow: 1;
        display: flex;
        flex-direction: column;
    }
    
    .card-content h3 {
        margin: 0 0 0.5rem 0;
    }

    .card-content p {
        margin: 0 0 1rem 0;
        flex-grow: 1;
        color: #555;
    }
    
    .card-tags {
        margin-bottom: 1rem;
    }
    
    .card-tags span {
        display: inline-block;
        background: #e9ecef;
        color: #495057;
        padding: 0.25rem 0.75rem;
        border-radius: 12px;
        font-size: 0.8rem;
        margin-right: 0.5rem;
        margin-bottom: 0.5rem;
    }

    .card-links a {
        text-decoration: none;
        color: #0077cc;
        font-weight: bold;
        margin-right: 1rem;
    }

    @media (max-width: 992px) {
        .projects-grid {
            grid-template-columns: repeat(2, 1fr);
        }
    }

    @media (max-width: 768px) {
        .projects-grid {
            grid-template-columns: 1fr;
        }
    }
    
    /* --- CONTACT SECTION --- */
    #contact {
        padding: 2rem 0;
        text-align: center;
    }

    #contact .contact-container {
        max-width: 600px; /* Back to original width */
        margin: 0 auto;
    }

    #contact .intro-text {
        font-size: 1.1rem;
        margin-bottom: 2rem;
    }
    
    .contact-details {
        font-size: 1.1rem;
        line-height: 2;
    }

    .contact-details a {
        color: #0077cc;
        text-decoration: none;
    }
    
    .contact-details a:hover {
        text-decoration: underline;
    }

    /* Reduce gap between items */
    .project-item {
      margin: 0.4rem 0;
    }

    #projects h3 {
      margin-top: 1.8rem;
      margin-bottom: 0.6rem;
    }

    .project-item h4 {
      margin: 0;
    }

    .project-item p {
      margin: 0.2rem 0;
      color: #444;
      font-size: 0.95rem;
    }

    .project-item a {
      display: inline-block;
      margin-top: 0.15rem;
      color: #0077cc;
      font-weight: bold;
      text-decoration: none;
      font-size: 0.92rem;
    }

    .project-item a:hover {
      text-decoration: underline;
    }

    .oms-note {
      margin-top: 0.8rem;
      font-size: 0.9rem;
      color: #0077cc;
      font-weight: bold;
    }

  </style>
</head>
<body>
  <div class="container">

    <section class="profile">
      <img src="pic.jpg" alt="Kiran George" />
      <div class="profile-text">
        <h1>Kiran George</h1>
        <p>
          AI Engineer making machines see and think. Robotics @ Georgia Tech.
        </p>
        <div class="links">
          <a href="https://github.com/kirang96" target="_blank">GitHub</a>
          <a href="mailto:kiran.geo96@gmail.com">Email</a>
        </div>
      </div>
    </section>

    <section>
        <ul class="timeline">
          <li class="timeline-item">
            <div class="timeline-logo"><span>FL</span></div>
            <div class="timeline-content">
              <h3>AI Engineer, Fission Labs</h3>
              <span>Sep 2022 - Present</span>
              <p>
                As an AI Engineer, I'm an active contributor to Flotorch, our open-source LLM and agentic orchestration framework. My work there involves developing core features, including RAG orchestration on AWS with models from Bedrock and OpenAI, and co-developing an agentic evaluation SDK. In computer vision, I engineered a 3D measurement solution using COLMAP and Open3D that cut client storage costs by 40%, and optimized an inference pipeline with MobileSAM and TensorRT, boosting processing speeds by 25%.
              </p>
            </div>
          </li>
          <li class="timeline-item">
            <div class="timeline-logo"><span>FL</span></div>
            <div class="timeline-content">
              <h3>AI Engineer Intern, Fission Labs</h3>
              <span>Jun 2022 - Sept 2022</span>
              <p>Conducted R&D on multiview geometry, photogrammetry, and various camera parameters for high-precision imaging systems.</p>
            </div>
          </li>
          <li class="timeline-item">
            <div class="timeline-logo"><span>AA</span></div>
            <div class="timeline-content">
              <h3>Computer Vision Intern, Artenal Agrotech</h3>
              <span>Nov 2021 - May 2022</span>
              <p>Fine-tuned a YOLO object detection model for a fruit harvesting robot and experimented with Nvidia Isaac SDK and SIM for robot navigation.</p>
            </div>
          </li>

          <li class="timeline-item">
            <div class="timeline-logo"><span>GT</span></div>
            <div class="timeline-content">
              <h3>Master of Computer Science</h3>
              <span>Georgia Institute of Technology | 2024 - present</span>
              <p>Specialisation in Computational Perception and Robotics. Relevant coursework includes Human-computer interaction, Computational photography, and knowledge based AI.</p>
            </div>
          </li>
           <li class="timeline-item">
            <div class="timeline-logo"><span>NC</span></div>
            <div class="timeline-content">
              <h3>Mechatronics Engineering</h3>
              <span>Nehru College of Engineering and Research Center | 2015 - 2019</span>
              <p>Relevant coursework includes Digital image processing, Robotics, Machine vision, Embedded systems, and C programming.</p>
            </div>
          </li>
        </ul>
      </section>

    <hr style="border: 1px solid #eee; margin: 3rem 0;">

    <section id="projects">
    <h2 style="text-align:center;">Projects</h2>

    <!-- Pet Projects -->
    <h3>Pet Projects</h3>
    <div class="project-item">
      <h4>Daxch: Agent based trading assistant</h4>
      <p>
        A modular trading platform using a multi-agent system for multiple stock evaluation strategies. It evaluates stocks using different strategies by collecting data about a stock and provide useful information the user can use to make an informed decision.
      </p>
      <!-- <a href="#">View Project</a> -->
    </div>

    <div class="project-item">
      <h4>NLP-Powered Air Quality Prediction</h4>
      <p>
        An experimental project where I attempted to predict the air quality of the future dates using real data. I collected data from pollution control board and cleaned it to make it usable. This was then used to train different models like LSTM, GRU and conv-LSTM to predict AQI in future dates.
      </p>
      <a href="https://github.com/Kirang96/Air-quality-prediction">View Project</a>
    </div>

    <div class="project-item">
      <h4>Caption Quest</h4>
      <p>
        This is something that mimics the Google photos search feature where we can  find images by type in the content of the image.
It uses MiniCPM model for creating captions of videos and images and saved in metadata of images. The metadata is then retrieved to find the right image. This can be used to create a local searchable image storage device.
      </p>
      <!-- <a href="#">View Project</a> -->
    </div>

    <!-- OMSCS Computational Photography Projects -->
    <h3>OMSCS Computational Photography Projects</h3>

    <div class="project-item">
      <h4>Pyramid Blending</h4>
      <p>
        Pyramid blending is an image blending strategy still being used in creating panoramas and other OpenCV operations like HDR.
This project involves blending two images using laplacian pyramid. We have two images where some object from the first image is required to be placed in the second image. We have a binary mask highlighting this area. The program will first create different layers for a pyramid by reducing and  expanding the input images. These are then used to create Gaussian pyramid and Laplacian pyramids. We do the process for both the images and the images are blended at the masked area by a weighing function at different layers of the pyramid. All the layers are then collapsed to form a single output image.
      </p>
        <p class="oms-note">
    Source code is available upon request. Not publicly shared due to university plagiarism concerns.
  </p>
    </div>

    <div class="project-item">
      <h4>Panoramas</h4>
      <p>
        Panoramas are long images created by sticting together multiple images, which is a feature in all the modern mobile devices.
In this project I created a pipeline to generate panoramas using given images. It does not use any stitching functions. The program will detect features using ORB, match them and find the homography between images and then put them into a warped canvas. Those images are then blended together using alpha weights to form a smooth panorama.
      </p>
        <p class="oms-note">
    Source code is available upon request. Not publicly shared due to university plagiarism concerns.
  </p>
    </div>

    <div class="project-item">
      <h4>High Dynamic Range (HDR)</h4>
      <p>
        HDR is popular in modern cameras to generate images with evenly distributed light. In this project, the program uses an exposure stack (images of different exposure brackets) to estimate camera's response curve by sampling intensities. That curve and exposure times are used to compute radiance maps. Radiance maps are then tone mapped to form HDR images. 
      </p>
        <p class="oms-note">
    Source code is available upon request. Not publicly shared due to university plagiarism concerns.
  </p>
    </div>

    <div class="project-item">
      <h4>Video Textures</h4>
      <p>
        Video textures are infinitely long looped videos created from normal videos.
The program first finds the similarity matrix of all the frames in the video. It then computes a temporal transition cost which helps to find the dynamics in the video. Using a scoring function, the best looping segment is then selected by sampling the frames. These frames are then used to synthesize an infinitely long video.
      </p>
        <p class="oms-note">
    Source code is available upon request. Not publicly shared due to university plagiarism concerns.
  </p>
    </div>

    <div class="project-item">
      <h4>Object Removal</h4>
      <p>
        Latest object removal programs uses deep learning. This is an implementation of a paper from Criminisi. The object to be removed is given as a binary mask. The removal is done by filling the areas which has certain characteristics from the periphery. So, the program will first detect the boundary of the area to be removed and then start with patches on it. For each patch, it calculates a priority score based on a confidence (how much of the patch is known) and a data term whcih tells the strcture direction. It then searches the known area of the image that matches that patch in LAB color space. The selected patch is copied over to the missing area. This repeated process help fill the entire image using other pixels from the same image. Some of the functions are optimized to run faster using numba jit and numpy matrix multiplication.
      </p>
        <p class="oms-note">
    Source code is available upon request. Not publicly shared due to university plagiarism concerns.
  </p>
    </div>

  </section>

    <hr style="border: 1px solid #eee; margin: 3rem 0;">

    <section id="contact">
        <div class="contact-container">
            <h2>Get In Touch</h2>
            <p class="intro-text">I'm always open to discussing new projects, creative ideas, or opportunities to be part of your visions. Feel free to reach out.</p>
            <div class="contact-details">
                <p><strong>Email:</strong> <a href="mailto:kiran.geo96@gmail.com">kiran.geo96@gmail.com</a></p>
                <p><strong>Phone:</strong> <a href="tel:+917907150993">+91 790-715-0993</a></p>
                <p><strong>Location:</strong> Kerala, India</p>
            </div>
        </div>
    </section>

  </div>
</body>
</html>